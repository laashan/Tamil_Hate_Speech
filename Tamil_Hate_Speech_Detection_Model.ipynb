{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGhPcco9R1GQghrOdfgctT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laashan/Tamil_Hate_Speech/blob/main/Tamil_Hate_Speech_Detection_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkSQUcRtjcw6",
        "outputId": "f0602cef-13b7-4dd4-85af-d4ab1ca3a6c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tamil_Hate_Speech'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 6 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (9/9), 15.95 KiB | 2.28 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/laashan/Tamil_Hate_Speech.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Tamil_Hate_Speech"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nY_hOGqjxWV",
        "outputId": "c6649022-8f0c-4624-de61-105a09604bbe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Tamil_Hate_Speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load the saved pipeline\n",
        "pipeline = joblib.load('/content/Tamil_Hate_Speech/hate_speech_model.pkl')\n",
        "\n",
        "# Function to predict whether a given piece of text is hate speech or not\n",
        "def predict_hate_speech(text):\n",
        "   prediction = pipeline.predict([text]) # Predict the label for the input text\n",
        "   if prediction == 0:\n",
        "        return \"This text is not hate speech.\" # Return this if the predicted label is 0\n",
        "   else:\n",
        "        return \"This text is hate speech.\" # Return this if the predicted label is 1\n",
        "\n",
        "# Example usage:\n",
        "print(predict_hate_speech(\"‡ÆÆ‡ØÇ‡Æú‡Øç‡Æú‡Æø‡ÆØ ‡Æ™‡Æ≤ ‡Æ™‡Æ≤‡Æ©‡ØÅ ‡Æµ‡Æö‡Øç‡Æö‡ØÅ‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Ææ ü§§ü§§ü§§ ‡ÆÖ‡Æ¥‡Æï‡Ææ ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï ‡Æü‡Æø ‡ÆÆ‡ØÅ‡Æ£‡Øç‡Æü ,\")) # Test the function with an example text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uggP6dvsj3gN",
        "outputId": "4a12672c-0827-4ba5-b934-55f5b7c3fb46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This text is hate speech.\n"
          ]
        }
      ]
    }
  ]
}